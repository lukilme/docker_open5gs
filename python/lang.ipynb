{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72f3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ollama_client import OllamaClient\n",
    "from src.database_client import DatabaseClient\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import requests\n",
    "import re\n",
    "import sqlglot\n",
    "from sqlglot.expressions import Column\n",
    "from sqlglot.errors import ParseError\n",
    "import sqlglot\n",
    "from sqlglot import expressions as exp\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.ollama_base_url = \"http://localhost:11434\"\n",
    "        self.database = DatabaseClient()\n",
    "        #tem que estar em inglês\n",
    "        self.table_schema = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS metric (\n",
    "            time TIMESTAMPTZ NOT NULL PRIMARY KEY, -- Metric timestamp\n",
    "            fivegs_amffunction_rm_registeredsubnbr INT, -- Number of registered subscribers\n",
    "            fivegs_amffunction_rm_regmobreq INT, -- Mobility registration update requests\n",
    "            fivegs_amffunction_rm_regmobsucc INT, -- Successful mobility registration updates\n",
    "            fivegs_amffunction_rm_regmobfail INT, -- Failed mobility registration updates\n",
    "            fivegs_smffunction_sm_sessionnbr INT, -- Number of active sessions\n",
    "            fivegs_smffunction_sm_pdusessioncreationreq INT, -- PDU session creation requests\n",
    "            fivegs_smffunction_sm_pdusessioncreationsucc INT, -- Successful PDU session creations\n",
    "            fivegs_ep_n3_gtp_indatapktn3upf INT, -- Uplink throughput on N3 interface\n",
    "            fivegs_ep_n3_gtp_outdatapktn3upf INT, -- Downlink throughput on N3 interface\n",
    "            fivegs_upffunction_upf_sessionnbr INT, -- Average number of PDU sessions\n",
    "            fivegs_smffunction_upf_qos_flow_nbr INT, -- Number of active QoS flows\n",
    "            fivegs_upffunction_sm_n4sessionreport INT, -- N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionreportsucc INT, -- Successful N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionestabreq INT, -- N4 session establishment requests\n",
    "            fivegs_upffunction_sm_n4sessionestabfail INT, -- Failed N4 session establishments\n",
    "            softmodern_bler_dl INT, -- Block error rate - downlink\n",
    "            softmodern_bler_ul INT, -- Block error rate - uplink\n",
    "            softmodern_rsrp INT, -- Received signal power\n",
    "            pfcp_sessions_active INT -- Used for testing value changes\n",
    "        );\n",
    "        Get the current 5G network performance metrics, including throughput, latency and packet loss rates.\n",
    "        \"\"\"\n",
    "        \n",
    "    def call_ollama(self, model : str, prompt : str, system_prompt: str = None) -> str:\n",
    "\n",
    "        try:\n",
    "            url = f\"{self.ollama_base_url}/api/generate\"\n",
    "            payload = {\n",
    "                \"model\": model,\n",
    "                \"prompt\":prompt,\n",
    "                \"stream\":False,\n",
    "                \"options\":{\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"num_predict\": 1000\n",
    "                }\n",
    "            }\n",
    "            if system_prompt:\n",
    "                payload[\"system\"] = system_prompt\n",
    "            response = requests.post(url, json=payload, timeout=120)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            return response.json()[\"response\"].strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def translate_and_process_question(self, question: str) -> str:\n",
    "        # self.table_schema\n",
    "        system_prompt = \"\"\"\n",
    "        Você é um assistente especializado em tradução e processamento de perguntas para consultas SQL.\n",
    "        Sua tarefa é:\n",
    "        1. Traduzir a pergunta do português para o inglês\n",
    "        2. Reformular a pergunta para ser mais específica e clara para geração de SQL\n",
    "        3. Incluir contexto técnico relevante sobre métricas de redes 5G quando apropriado\n",
    "        4. Manter o significado original mas torná-la mais precisa\n",
    "        \n",
    "        Responda apenas com a pergunta traduzida e processada, sem explicações adicionais.\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Pergunta original em português: \"{question}\"\n",
    "        \n",
    "        Traduza para inglês e processe para ser mais específica para geração de SQL sobre métricas de rede 5G.\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(\"Etapa 1: Traduzindo e processando pergunta...\")\n",
    "        processed_question = self.call_ollama(\"llama3.2:latest\", prompt, system_prompt)\n",
    "        logger.info(f\"Pergunta processada: {processed_question}\")\n",
    "        \n",
    "        return processed_question\n",
    "    \n",
    "    def execute_sql_query(self, sql_query: str) -> Tuple[list, str]:\n",
    "        try:\n",
    "            logger.info(\"Etapa 3: Executando query SQL...\")\n",
    "            return self.database.execute(sql_query)                    \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erro ao executar query SQL: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return [], error_msg\n",
    "\n",
    "    def generate_sql_query(self, processed_question: str, max_retries: int = 3) -> str:\n",
    "        system_prompt = \"\"\"\n",
    "        You are an expert SQL query generator for PostgreSQL. Generate precise SQL queries based on the user's question.\n",
    "        Always use proper SQL syntax and consider performance optimizations.\n",
    "        Focus on the specific metrics requested and use appropriate aggregations and filters.\n",
    "        Return only the SQL query without any explanations or markdown formatting.\n",
    "        \"\"\"\n",
    "\n",
    "        available_columns = self._extract_column_names()\n",
    "\n",
    "        base_prompt = f\"\"\"\n",
    "        Database schema:\n",
    "        {self.table_schema}\n",
    "\n",
    "        Available columns in 'metric' table:\n",
    "        {', '.join(available_columns)}\n",
    "\n",
    "        User question: {processed_question}\n",
    "\n",
    "        Generate a SQL query to answer this question. Consider:\n",
    "        - The table name is 'metric'\n",
    "        - Use appropriate time filtering when needed\n",
    "        - Apply proper aggregations (SUM, AVG, COUNT, etc.)\n",
    "        - Include relevant columns based on the question\n",
    "        - Use proper PostgreSQL syntax\n",
    "        - ONLY use column names that exist in the available columns list above\n",
    "\n",
    "        Important constraints:\n",
    "        - Table name: 'metric'\n",
    "        - Time column: 'time' (TIMESTAMPTZ)\n",
    "        - NEVER use nested aggregate functions like AVG(SUM(...))\n",
    "        - Use subqueries for complex aggregations\n",
    "        - Use proper time filtering with PostgreSQL date functions\n",
    "        - Include appropriate GROUP BY clauses\n",
    "        - Use LIMIT when showing recent data\n",
    "        - NEVER use aggregate functions in GROUP BY clause\n",
    "        - Only reference columns that exist in the available columns list\n",
    "\n",
    "        Examples of VALID patterns:\n",
    "        - SELECT AVG(column_name) FROM metric WHERE time >= NOW() - INTERVAL '1 hour'\n",
    "        - SELECT date_trunc('hour', time), SUM(column_name) FROM metric GROUP BY date_trunc('hour', time)\n",
    "        - SELECT AVG(daily_total) FROM (SELECT DATE(time), SUM(column_name) as daily_total FROM metric GROUP BY DATE(time)) subq\n",
    "        - SELECT time, column_name FROM metric ORDER BY time DESC LIMIT 10\n",
    "\n",
    "        Examples of INVALID patterns (DO NOT USE):\n",
    "        - SELECT AVG(SUM(column_name)) FROM metric -- INVALID: nested aggregates\n",
    "        - SELECT SUM(AVG(column_name)) FROM metric -- INVALID: nested aggregates\n",
    "        - SELECT time, SUM(column_name) FROM metric GROUP BY COUNT(other_column) -- INVALID: aggregate in GROUP BY\n",
    "        - SELECT nonexistent_column FROM metric -- INVALID: column doesn't exist\n",
    "\n",
    "        Generate only the SQL query:\n",
    "        \"\"\"\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < max_retries:\n",
    "            logger.info(f\"Etapa 2: Tentativa {attempt + 1} de {max_retries} para gerar query SQL...\")\n",
    "            sql_query = self.call_ollama(\"llama3.2:latest\", base_prompt, system_prompt)\n",
    "\n",
    "            sql_query = re.sub(r'```sql\\n?', '', sql_query)\n",
    "            sql_query = re.sub(r'```\\n?', '', sql_query)\n",
    "            sql_query = sql_query.strip()\n",
    "\n",
    "            validation_errors = None\n",
    "            # self.validate_postgres_sql(sql_query, available_columns)\n",
    "            if not validation_errors:\n",
    "                logger.info(f\"Query SQL gerada com sucesso: {sql_query}\")\n",
    "                return sql_query\n",
    "            else:\n",
    "                logger.warning(f\"Tentativa {attempt + 1} falhou com erros: {validation_errors}\")\n",
    "                attempt += 1\n",
    "\n",
    "        logger.error(\"Falha ao gerar uma query SQL válida após várias tentativas.\")\n",
    "        raise ValueError(\"Não foi possível gerar uma query SQL válida.\")\n",
    "\n",
    "\n",
    "    def _extract_column_names(self) -> list:\n",
    "        \"\"\"Extract column names from the table schema\"\"\"\n",
    "        try:\n",
    "\n",
    "            columns = []\n",
    "            if hasattr(self, 'table_schema') and self.table_schema:\n",
    "                if isinstance(self.table_schema, str):\n",
    "                    import re\n",
    "                    column_matches = re.findall(r'(\\w+)\\s+(?:INTEGER|VARCHAR|TEXT|TIMESTAMPTZ|NUMERIC|FLOAT|DOUBLE)', \n",
    "                                            self.table_schema, re.IGNORECASE)\n",
    "                    columns = column_matches\n",
    "                \n",
    "            if not columns:\n",
    "                try:\n",
    "                    query = \"\"\"\n",
    "                    SELECT column_name \n",
    "                    FROM information_schema.columns \n",
    "                    WHERE table_name = 'metric' \n",
    "                    ORDER BY ordinal_position\n",
    "                    \"\"\"\n",
    "                    result = self.db_client.execute_query(query)\n",
    "                    columns = [row[0] for row in result]\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not fetch column names: {e}\")\n",
    "                    columns = ['time']\n",
    "            \n",
    "            return columns\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting column names: {e}\")\n",
    "            return ['time']\n",
    "\n",
    "    \n",
    "\n",
    "    def validate_postgres_sql(self,sql_query: str, available_columns: list) -> list:\n",
    "        errors = []\n",
    "\n",
    "        try:\n",
    "            # Define parsing para PostgreSQL\n",
    "            parsed = sqlglot.parse_one(sql_query, read=\"postgres\")\n",
    "        except sqlglot.errors.ParseError as e:\n",
    "            return [f\"SQL syntax error (PostgreSQL): {e}\"]\n",
    "\n",
    "        used_columns = set()\n",
    "        agg_stack = []\n",
    "\n",
    "        def visit(node, inside_group_by=False):\n",
    "            # Coleta colunas\n",
    "            if isinstance(node, exp.Column):\n",
    "                used_columns.add(node.name)\n",
    "\n",
    "            # Detecta agregações aninhadas\n",
    "            if isinstance(node, exp.AggFunc):\n",
    "                if agg_stack:\n",
    "                    errors.append(\"Nested aggregate functions detected.\")\n",
    "                agg_stack.append(node)\n",
    "\n",
    "            # Detecta agregações dentro de GROUP BY\n",
    "            if inside_group_by and isinstance(node, exp.AggFunc):\n",
    "                errors.append(\"Aggregate function inside GROUP BY clause.\")\n",
    "\n",
    "            # Recursão nos filhos da árvore\n",
    "            for child in node.args.values():\n",
    "                if isinstance(child, list):\n",
    "                    for item in child:\n",
    "                        visit(item, inside_group_by=inside_group_by)\n",
    "                elif isinstance(child, exp.Expression):\n",
    "                    visit(child, inside_group_by=inside_group_by)\n",
    "\n",
    "            if isinstance(node, exp.AggFunc):\n",
    "                agg_stack.pop()\n",
    "\n",
    "        # Visita geral\n",
    "        visit(parsed)\n",
    "\n",
    "        # Verificar GROUP BY separadamente\n",
    "        group_by_exprs = parsed.args.get(\"group\", [])\n",
    "        for expr in group_by_exprs:\n",
    "            visit(expr, inside_group_by=True)\n",
    "\n",
    "        # Verifica colunas não existentes\n",
    "        missing_columns = [col for col in used_columns if col not in available_columns]\n",
    "        if missing_columns:\n",
    "            errors.append(f\"Potential missing columns: {missing_columns}\")\n",
    "\n",
    "        return errors\n",
    "\n",
    "    def interpret_results(self, original_question: str, sql_query: str, \n",
    "                         results: list, execution_status: str) -> str:\n",
    "        system_prompt = \"\"\"\n",
    "        Você é um assistente especializado em análise de dados de redes 5G.\n",
    "        Sua tarefa é interpretar os resultados de consultas SQL e fornecer uma resposta clara em português.\n",
    "        \n",
    "        Diretrizes:\n",
    "        1. Responda em português brasileiro\n",
    "        2. Seja claro e objetivo\n",
    "        3. Forneça insights relevantes sobre os dados\n",
    "        4. Explique o que os números significam no contexto de redes 5G\n",
    "        5. Se houver problemas com a query, explique de forma compreensível\n",
    "        6. Use formatação clara para apresentar os dados\n",
    "        \"\"\"\n",
    "        \n",
    "        if results:\n",
    "            results_summary = f\"Resultados encontrados: {len(results)} registros\\n\"\n",
    "            results_summary += f\"Primeiros resultados:\\n{json.dumps(results[:5], indent=2, default=str)}\"\n",
    "        else:\n",
    "            results_summary = \"Nenhum resultado encontrado ou erro na execução.\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Pergunta original do usuário: \"{original_question}\"\n",
    "        \n",
    "        Query SQL executada: {sql_query}\n",
    "        \n",
    "        Status da execução: {execution_status}\n",
    "        \n",
    "        {results_summary}\n",
    "        \n",
    "        Forneça uma resposta completa em português interpretando estes resultados para o usuário.\n",
    "        Se houver dados, analise-os e forneça insights relevantes.\n",
    "        Se houver erros, explique o que aconteceu de forma compreensível.\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(\"Etapa 4: Interpretando resultados...\")\n",
    "        interpretation = self.call_ollama(\"llama3.2:latest\", prompt, system_prompt)\n",
    "        \n",
    "        return interpretation\n",
    "\n",
    "    def process_question(self, question: str):\n",
    "        start_time = datetime.now()\n",
    "        try:\n",
    "            processed_question = self.translate_and_process_question(question)\n",
    "\n",
    "            sql_query = self.generate_sql_query(processed_question)\n",
    "\n",
    "            results, execution_status = self.execute_sql_query(sql_query)\n",
    "\n",
    "            interpretation = self.interpret_results(\n",
    "                question, sql_query, results, execution_status\n",
    "            )\n",
    "\n",
    "            end_time = datetime.now()\n",
    "            processing_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"original_question\": question,\n",
    "                \"processed_question\": processed_question,\n",
    "                \"sql_query\": sql_query,\n",
    "                \"execution_status\": execution_status,\n",
    "                \"results_count\": len(results),\n",
    "                \"results\": results,\n",
    "                \"interpretation\": interpretation,\n",
    "                \"processing_time_seconds\": processing_time,\n",
    "                \"timestamp\": start_time.isoformat()\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_msg = f\"Erro no pipeline: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            \n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": error_msg,\n",
    "                \"original_question\": question,\n",
    "                \"timestamp\": start_time.isoformat()\n",
    "            }\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ee5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Number of active subscribers in the 5G network.\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "INFO:__main__:Query SQL gerada com sucesso: SELECT fivegs_amffunction_rm_registeredsubnbr FROM metric WHERE time >= NOW() - INTERVAL '1 hour'\n",
      "INFO:__main__:Etapa 3: Executando query SQL...\n",
      "INFO:__main__:Etapa 4: Interpretando resultados...\n",
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído em 269.79s\n",
      "Resultados encontrados: 63\n",
      "Query SQL: SELECT fivegs_amffunction_rm_registeredsubnbr FROM metric WHERE time >= NOW() - INTERVAL '1 hour'\n",
      "Interpretação: **Resposta do Assistente**\n",
      "\n",
      "Olá! Estou aqui para ajudar a interpretar os resultados da sua consulta SQL.\n",
      "\n",
      "**Resumo dos Resultados**\n",
      "\n",
      "A consulta SQL executada foi bem-sucedida e retornou 63 registros. No entanto, é importante notar que os primeiros resultados apresentam apenas cinco registros com o valor \"0\" para a coluna \"fivegs_amffunction_rm_registeredsubnbr\". Isso sugere que os registros iniciais podem não estar corretos ou podem ser um erro de carregamento.\n",
      "\n",
      "**Análise dos Dados**\n",
      "\n",
      "Para entender melhor o número total de assinantes registrados atualmente, precisamos analisar os dados mais a fundo. A coluna \"fivegs_amffunction_rm_registeredsubnbr\" representa o número de assinantes registrados no sistema. O valor \"0\" nos primeiros registros pode ser um erro de carregamento ou uma falha na consulta.\n",
      "\n",
      "**Insights Relevantes**\n",
      "\n",
      "Com base nos dados, podemos concluir que:\n",
      "\n",
      "*   A maioria dos assinantes (63 - 5 = 58) estão registrados atualmente.\n",
      "*   O valor \"0\" nos primeiros registros pode ser um erro de carregamento ou uma falha na consulta SQL.\n",
      "*   É importante verificar os dados mais a fundo para garantir que sejam precisos e confiáveis.\n",
      "\n",
      "**O que os Números Significam no Contexto de Redes 5G**\n",
      "\n",
      "No contexto de redes 5G, o número de assinantes registrados é um indicador importante da adoção e do sucesso da rede. Um número alto de assinantes pode indicar uma boa cobertura e uma alta demanda por serviços de dados.\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "Em resumo, os resultados da consulta SQL sugerem que 58 assinantes estão registrados atualmente, com apenas cinco registros iniciais apresentando um valor \"0\". É importante verificar os dados mais a fundo para garantir que sejam precisos e confiáveis. Se você tiver alguma dúvida adicional ou precisar de ajuda para analisar os dados, estou aqui para ajudar!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Which is the session PDU success rate for the last week in 5G network?\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "INFO:__main__:Query SQL gerada com sucesso: SELECT \n",
      "    time,\n",
      "    AVG(fivegs_smffunction_sm_pdusessioncreationsucc) AS fivegs_smffunction_sm_pdusessioncreationsucc_avg\n",
      "FROM \n",
      "    metric\n",
      "WHERE \n",
      "    time >= NOW() - INTERVAL '1 week'\n",
      "GROUP BY \n",
      "    time\n",
      "ORDER BY \n",
      "    time DESC\n",
      "LIMIT 10;\n",
      "INFO:__main__:Etapa 3: Executando query SQL...\n",
      "INFO:__main__:Etapa 4: Interpretando resultados...\n",
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído em 125.46s\n",
      "Resultados encontrados: 10\n",
      "Query SQL: SELECT \n",
      "    time,\n",
      "    AVG(fivegs_smffunction_sm_pdusessioncreationsucc) AS fivegs_smffunction_sm_pdusessioncreationsucc_avg\n",
      "FROM \n",
      "    metric\n",
      "WHERE \n",
      "    time >= NOW() - INTERVAL '1 week'\n",
      "GROUP BY \n",
      "    time\n",
      "ORDER BY \n",
      "    time DESC\n",
      "LIMIT 10;\n",
      "Interpretação: **Resposta ao Pergunta Original**\n",
      "\n",
      "A taxa de sucesso das sessões PDU na última semana é um indicador importante para avaliar a eficiência da rede 5G. Com base nos resultados da consulta SQL, podemos analisar os dados e fornecer insights relevantes.\n",
      "\n",
      "**Análise dos Resultados**\n",
      "\n",
      "Os resultados mostram que a média de sucesso das sessões PDU na última semana é de aproximadamente **0E-20**, o que significa que cerca de 99,999% das sessões PDU foram bem-sucedidas. Isso é um indicativo muito alto e sugere que a rede 5G está funcionando de forma eficiente.\n",
      "\n",
      "**Insights Relevantes**\n",
      "\n",
      "* A alta taxa de sucesso das sessões PDU indica que a rede 5G está lidando bem com o tráfego de dados.\n",
      "* No entanto, é importante notar que a média de sucesso é muito alta, o que pode indicar que há poucas falhas ou erros na rede.\n",
      "* Além disso, é interessante observar que os registros estão sendo ordenados em ordem descendente do tempo, o que sugere que as falhas ou erros na rede estão ocorrendo em um período de tempo muito curto.\n",
      "\n",
      "**O que os Números Significam**\n",
      "\n",
      "A média de sucesso das sessões PDU é um indicador importante para avaliar a eficiência da rede 5G. Em geral, uma taxa de sucesso acima de 99% é considerada alta e indica que a rede está funcionando de forma eficiente.\n",
      "\n",
      "**Erros ou Problemas**\n",
      "\n",
      "Nesse caso, não há erros ou problemas com a consulta SQL. A execução foi bem-sucedida e os resultados foram obtidos corretamente. No entanto, é importante notar que a média de sucesso é muito alta, o que pode indicar que há poucas falhas ou erros na rede.\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "Em resumo, os resultados da consulta SQL mostram que a taxa de sucesso das sessões PDU na última semana é alta e indica que a rede 5G está funcionando de forma eficiente. É importante monitorar esses indicadores para garantir que a rede continue a funcionar de forma segura e eficiente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Show the average upload and download throughput over the last 24 hours, including relevant metrics for 5G network performance.\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "INFO:__main__:Query SQL gerada com sucesso: SELECT \n",
      "    AVG(CASE WHEN column_name = 'fivegs_ep_n3_gtp_outdatapktn3upf' THEN value ELSE NULL END) AS avg_upload_throughput,\n",
      "    AVG(CASE WHEN column_name = 'fivegs_ep_n3_gtp_indatapktn3upf' THEN value ELSE NULL END) AS avg_download_throughput\n",
      "FROM \n",
      "    metric\n",
      "WHERE \n",
      "    time >= NOW() - INTERVAL '24 hour'\n",
      "ORDER BY \n",
      "    time DESC\n",
      "LIMIT 1;\n",
      "INFO:__main__:Etapa 3: Executando query SQL...\n",
      "ERROR:src.database_client:Erro SQL: column \"column_name\" does not exist\n",
      "LINE 2:     AVG(CASE WHEN column_name = 'fivegs_ep_n3_gtp_outdatapkt...\n",
      "                          ^\n",
      "\n",
      "INFO:__main__:Etapa 4: Interpretando resultados...\n",
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído em 122.97s\n",
      "Resultados encontrados: 0\n",
      "Query SQL: SELECT \n",
      "    AVG(CASE WHEN column_name = 'fivegs_ep_n3_gtp_outdatapktn3upf' THEN value ELSE NULL END) AS avg_upload_throughput,\n",
      "    AVG(CASE WHEN column_name = 'fivegs_ep_n3_gtp_indatapktn3upf' THEN value ELSE NULL END) AS avg_download_throughput\n",
      "FROM \n",
      "    metric\n",
      "WHERE \n",
      "    time >= NOW() - INTERVAL '24 hour'\n",
      "ORDER BY \n",
      "    time DESC\n",
      "LIMIT 1;\n",
      "Interpretação: **Análise dos Resultados**\n",
      "\n",
      "Infelizmente, não foi possível executar a consulta SQL original devido ao erro \"column 'column_name' does not exist\". Isso significa que o nome da coluna especificada no filtro `CASE WHEN` não existe na tabela `metric`.\n",
      "\n",
      "**O que aconteceu?**\n",
      "\n",
      "A probabilidade é de que o nome da coluna seja incorreto ou não esteja sendo usado corretamente. É possível que a coluna tenha um nome diferente do que foi especificado, ou talvez haja um erro de digitação.\n",
      "\n",
      "**Sugestões para resolver o problema**\n",
      "\n",
      "1. Verifique o nome da coluna: Revise a tabela `metric` e verifique se o nome da coluna é realmente 'fivegs_ep_n3_gtp_outdatapktn3upf' ou 'fivegs_ep_n3_gtp_indatapktn3upf'. Se não for, tente encontrar o nome correto.\n",
      "2. Verifique a tabela: Revise a tabela `metric` e verifique se as colunas existem com os nomes especificados. Você pode usar a consulta `SHOW COLUMNS FROM metric;` para verificar a lista de colunas da tabela.\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "Infelizmente, não foi possível fornecer os resultados solicitados devido ao erro no filtro de coluna. É necessário corrigir o nome da coluna ou verificar se há algum outro problema com a consulta. Se você precisar de ajuda adicional, sinta-se à vontade para perguntar.\n",
      "\n",
      "**Dicas adicionais**\n",
      "\n",
      "* Verifique a documentação da tabela `metric` e da base de dados para obter informações sobre as colunas disponíveis.\n",
      "* Use a consulta `DESCRIBE metric;` para verificar a estrutura da tabela e encontrar o nome correto da coluna.\n",
      "* Se você estiver trabalhando com um banco de dados específico, verifique se há algum problema de compatibilidade ou erros de digitação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Which is the block error rate for Uplink and Downlink as of today?\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "INFO:__main__:Query SQL gerada com sucesso: SELECT AVG(softmodern_bler_ul), AVG(softmodern_bler_dl) FROM metric WHERE time >= NOW()\n",
      "INFO:__main__:Etapa 3: Executando query SQL...\n",
      "INFO:__main__:Etapa 4: Interpretando resultados...\n",
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído em 96.72s\n",
      "Resultados encontrados: 1\n",
      "Query SQL: SELECT AVG(softmodern_bler_ul), AVG(softmodern_bler_dl) FROM metric WHERE time >= NOW()\n",
      "Interpretação: **Resposta do Assistente**\n",
      "\n",
      "Olá! Estou aqui para ajudar a interpretar os resultados da sua consulta SQL.\n",
      "\n",
      "Infelizmente, não há dados disponíveis para analisar. O resultado da consulta é um array vazio com apenas 1 registro, mas o valor médio de erro de bloco (softmodern_bler_ul e softmodern_bler_dl) está igual a null.\n",
      "\n",
      "**O que significa \"null\"?**\n",
      "\n",
      "Em SQL, o valor null indica que não há dados disponíveis para calcular. Nesse caso, isso significa que não há registros de erros de bloco disponíveis nos últimos minutos.\n",
      "\n",
      "**Por que isso pode acontecer?**\n",
      "\n",
      "Existem várias razões pelas quais os dados podem estar faltando:\n",
      "\n",
      "*   A rede 5G ainda está em desenvolvimento e pode haver problemas técnicos.\n",
      "*   Os dados podem não estar sendo coletados corretamente ou de forma contínua.\n",
      "*   Há um problema com a consulta SQL ou com o banco de dados.\n",
      "\n",
      "**O que fazer em seguida?**\n",
      "\n",
      "Para obter mais informações, você pode tentar:\n",
      "\n",
      "*   Verificar se os dados estão sendo coletados corretamente e se há algum problema com a rede 5G.\n",
      "*   Revisar a consulta SQL para garantir que está sendo executada corretamente.\n",
      "*   Contatar o suporte técnico do banco de dados ou da rede 5G para obter mais informações.\n",
      "\n",
      "Espero que isso ajude! Se tiver mais alguma pergunta, sinta-se à vontade para perguntar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Active sessions count in real-time.\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "INFO:__main__:Query SQL gerada com sucesso: SELECT AVG(fivegs_smffunction_sm_sessionnbr) FROM metric WHERE time >= NOW()\n",
      "INFO:__main__:Etapa 3: Executando query SQL...\n",
      "INFO:__main__:Etapa 4: Interpretando resultados...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído em 94.23s\n",
      "Resultados encontrados: 1\n",
      "Query SQL: SELECT AVG(fivegs_smffunction_sm_sessionnbr) FROM metric WHERE time >= NOW()\n",
      "Interpretação: **Resposta do Assistente**\n",
      "\n",
      "Olá! Estou aqui para ajudar a interpretar os resultados da sua consulta SQL.\n",
      "\n",
      "Infelizmente, não há dados disponíveis para fornecer uma resposta clara. O resultado da consulta é um único registro com o valor `null` no campo `avg`, que representa a média das sessões ativas.\n",
      "\n",
      "**O que significa \"null\"?**\n",
      "\n",
      "Em termos de redes 5G, a média das sessões ativas (ou seja, o número de conexões ativas) é um indicador importante para avaliar a capacidade da rede. No entanto, nesse caso, o valor `null` indica que não há dados disponíveis para calcular essa média.\n",
      "\n",
      "**Por que isso aconteceu?**\n",
      "\n",
      "É possível que a consulta SQL não tenha encontrado registros relevantes nos últimos minutos (o que é indicado pela condição `time >= NOW()`). Isso pode ocorrer se a rede 5G ainda estiver em processo de configuração ou se não haja muitas conexões ativas no momento.\n",
      "\n",
      "**O que fazer em seguida?**\n",
      "\n",
      "Para obter uma resposta mais precisa, você pode tentar ajustar a consulta SQL para incluir mais condições de tempo ou utilizar outras tabelas relacionadas para encontrar dados adicionais. Por exemplo:\n",
      "\n",
      "* `SELECT AVG(fivegs_smffunction_sm_sessionnbr) FROM metric WHERE time >= NOW() AND fivegs_smfdeviceid = 'ID do dispositivo'`\n",
      "* `SELECT AVG(fivegs_smffunction_sm_sessionnbr) FROM metric JOIN fivegs_smfdevice ON metric.fivegs_smfdeviceid = fivegs_smfdevice.id WHERE time >= NOW()`\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline()\n",
    "\n",
    "perguntas_exemplo = [\n",
    "        \"Quantos assinantes estão registrados atualmente?\",\n",
    "        \"Qual é a taxa de sucesso das sessões PDU na última semana?\",\n",
    "        \"Mostre o throughput médio de upload e download nas últimas 24 horas\",\n",
    "        \"Qual é a taxa de erro de bloco para uplink e downlink hoje?\",\n",
    "        \"Quantas sessões ativas existem no momento?\"\n",
    "    ]\n",
    "for pergunta in perguntas_exemplo:\n",
    "    resultado = pipe.process_question(pergunta)\n",
    "    if resultado[\"success\"]:\n",
    "        print(f\"Processamento concluído em {resultado['processing_time_seconds']:.2f}s\")\n",
    "        print(f\"Resultados encontrados: {resultado['results_count']}\")\n",
    "        print(f\"Query SQL: {resultado['sql_query']}\")\n",
    "        print(f\"Interpretação: {resultado['interpretation']}\")\n",
    "    else:\n",
    "        print(f\"Bola furada...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e891a6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "        Get the current 5G network performance metrics, including throughput, latency and packet loss rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e28c86",
   "metadata": {},
   "source": [
    "\"\"\" \n",
    "### Instructions:\n",
    "Your task is to convert a question into a SQL query, given a Postgres database schema.\n",
    "Adhere to these rules:\n",
    "- **Deliberately go through the question and database schema word by word** to appropriately answer the question\n",
    "- **Use Table Aliases** to prevent ambiguity. For example, `SELECT table1.col1, table2.col1 FROM table1 JOIN table2 ON table1.id = table2.id`.\n",
    "- When creating a ratio, always cast the numerator as float\n",
    "\n",
    "### Input:\n",
    "Generate a SQL query that answers the question create a query to analyze network status.\n",
    "This query will run on a database whose schema is represented in this string:\n",
    "        CREATE TABLE IF NOT EXISTS metric (\n",
    "            time TIMESTAMPTZ NOT NULL PRIMARY KEY, -- Metric timestamp\n",
    "            fivegs_amffunction_rm_registeredsubnbr INT, -- Number of registered subscribers\n",
    "            fivegs_amffunction_rm_regmobreq INT, -- Mobility registration update requests\n",
    "            fivegs_amffunction_rm_regmobsucc INT, -- Successful mobility registration updates\n",
    "            fivegs_amffunction_rm_regmobfail INT, -- Failed mobility registration updates\n",
    "            fivegs_smffunction_sm_sessionnbr INT, -- Number of active sessions\n",
    "            fivegs_smffunction_sm_pdusessioncreationreq INT, -- PDU session creation requests\n",
    "            fivegs_smffunction_sm_pdusessioncreationsucc INT, -- Successful PDU session creations\n",
    "            fivegs_ep_n3_gtp_indatapktn3upf INT, -- Uplink throughput on N3 interface\n",
    "            fivegs_ep_n3_gtp_outdatapktn3upf INT, -- Downlink throughput on N3 interface\n",
    "            fivegs_upffunction_upf_sessionnbr INT, -- Average number of PDU sessions\n",
    "            fivegs_smffunction_upf_qos_flow_nbr INT, -- Number of active QoS flows\n",
    "            fivegs_upffunction_sm_n4sessionreport INT, -- N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionreportsucc INT, -- Successful N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionestabreq INT, -- N4 session establishment requests\n",
    "            fivegs_upffunction_sm_n4sessionestabfail INT, -- Failed N4 session establishments\n",
    "            softmodern_bler_dl INT, -- Block error rate - downlink\n",
    "            softmodern_bler_ul INT, -- Block error rate - uplink\n",
    "            softmodern_rsrp INT, -- Received signal power\n",
    "            pfcp_sessions_active INT -- Used for testing value changes\n",
    "        );\n",
    "\n",
    "Based on your instructions and the fact , here is the SQL query I have generated to answer the question create a the number of active and failed sessions:\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
