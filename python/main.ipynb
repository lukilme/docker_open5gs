{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea198891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from metrics_dict import metrics_dict\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "        host=\"172.22.0.40\",\n",
    "        port=5432,\n",
    "        database=\"metrics\",\n",
    "        user=\"admin\",\n",
    "        password=\"admin123\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176f58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aux = None\n",
    "with connection.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM metric\")\n",
    "        for linha in cur.fetchall():\n",
    "            aux = pd.DataFrame(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40815824",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41b06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection.cursor() as cur:\n",
    "    cur.execute(\"SELECT * FROM metric ORDER BY time DESC\")\n",
    "    colnames = [desc[0] for desc in cur.description] \n",
    "    rows = cur.fetchall()\n",
    "    df = pd.DataFrame(rows, columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e4278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do modelo:\n",
      "Claro, vou explicar o conceito de aprendizado de máquina de forma simples:\n",
      "\n",
      "**O que é aprendizado de máquina?**\n",
      "\n",
      "O aprendizado de máquina é uma técnica de processamento de informações que permite a uma máquina aprender e se adaptar ao mundo ao seu redor. Ela não é apenas limitada à execução de instruções previsíveis, mas sim pode se especializar em tarefas específicas e melhorar suas habilidades com base na experiência.\n",
      "\n",
      "**Como funciona o aprendizado de máquina?**\n",
      "\n",
      "Agora vamos entender como isso funciona:\n",
      "\n",
      "1. **Dado**: São fornecidos dados de entrada que a máquina precisa processar, como imagens, textos ou áudio.\n",
      "2. **Algoritmo**: Um algoritmo é executado sobre os dados de entrada para transformá-los em um formato mais útil, como um modelo ou uma representação matemática.\n",
      "3. **Treinamento**: O algoritmo é treinado com base nos dados de entrada e é ajustado para melhorar seu desempenho ao longo do processo.\n",
      "4. **Teste**: Uma vez que o modelo estiver treinado, ele é testado em novos dados não vistos para avaliar sua precisão.\n",
      "\n",
      "**Exemplos práticos**\n",
      "\n",
      "*   Reconhecimento de palavras: uma máquina pode aprender a reconhecer as palavras de um dicionário e melhorar seu desempenho ao longo do tempo.\n",
      "*   Classificação de emails: uma máquina pode aprender a classificar os emails como spam ou não spam com base em características como o conteúdo e o remetente.\n",
      "*   Reconhecimento de imagens: uma máquina pode aprender a reconhecer objetos em imagens e categorizá-los.\n",
      "\n",
      "**Benefícios**\n",
      "\n",
      "O aprendizado de máquina oferece vários benefícios, incluindo:\n",
      "\n",
      "*   **Melhoria da precisão**: Com base na experiência, o algoritmo pode melhorar sua precisão ao longo do tempo.\n",
      "*   **Aumento da eficiência**: O algoritmo pode processar dados em velocidade e escala maior que a um ser humano.\n",
      "*   **Autonomia**: O aprendizado de máquina permite que as máquinas tomem decisões independentemente das instruções humanas.\n",
      "\n",
      "**Desafios**\n",
      "\n",
      "Apesar dos benefícios, o aprendizado de máquina também apresenta desafios:\n",
      "\n",
      "*   **Algorítimos complexos**: Os algoritmos podem ser difíceis de entender e implementar.\n",
      "*   **Dados inadequados**: Se os dados de entrada forem imprecisos ou incompletos, o modelo pode não funcionar corretamente.\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "O aprendizado de máquina é uma técnica poderosa que permite a máquinas aprender e se adaptar ao mundo ao seu redor. Ele oferece benefícios como melhoria da precisão, aumento da eficiência e autonomia, mas também apresenta desafios como algoritmos complexos e dados inadequados.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Mensagem enviada ao modelo\n",
    "payload = {\n",
    "    \"model\": \"llama3.2:latest\",\n",
    "    \"prompt\": \"Explique o que é aprendizado de máquina em termos simples.\"\n",
    "}\n",
    "\n",
    "# Faz a requisição para a API do Ollama\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", json=payload, stream=True)\n",
    "\n",
    "\n",
    "resposta_completa = \"\"\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        data = json.loads(line.decode(\"utf-8\"))\n",
    "        resposta_completa += data.get(\"response\", \"\")\n",
    "        if data.get(\"done\", False):  \n",
    "            break\n",
    "\n",
    "print(\"Resposta do modelo:\")\n",
    "print(resposta_completa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5b299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40c9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'table_name': 'metric'}], 'Sucesso')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49df767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Teste de listagem de modelos ===\n",
      "Modelos disponíveis: ['llama3.2:latest', 'sqlcoder:7b-q5_K_M', 'sqlcoder:latest']\n",
      "\n",
      "=== Teste de chamada básica ===\n",
      "Resposta: Uma API REST (Representational State of Resource) é um padrão de arquitetura para serviços web que se concentra na reutilização de recursos em um formato de dados simples, facilitando a comunicação entre sistemas e aplicativos.\n",
      "\n",
      "=== Teste de streaming ===\n",
      "Resposta em streaming: Claro! Aqui estão três benefícios de beber água:\n",
      "\n",
      "1. **Maior hidratação e melhor funcionamento do corpo**: A água é essencial para a vida, pois ajuda a manter o equilíbrio da água no corpo. Beber água suficiente ajuda a manter as funções corporais normais, como regulação da temperatura, transporte de nutrientes e oxigênio aos tecidos e eliminação de resíduos.\n",
      "\n",
      "2. **Melhora a saúde digestiva**: A água ajuda a prevenir a constipação e a indigestão, pois ajuda a dissolver as fibras alimentares e a melhorar a motilidade intestinal. Além disso, beber água antes das refeições pode ajudar a reduzir o risco de doenças gastrointestinais, como úlcera duodenal.\n",
      "\n",
      "3. **Apoia a perda de peso**: Beber água pode ajudar a aumentar a sensação de saciedade e reduzir a ingestão calórica. Além disso, a água ajuda a aumentar o metabolismo e a queimar gordura excessiva. Isso é especialmente útil para pessoas que estão tentando perder peso ou manter um peso saudável.\n",
      "\n",
      "Lembre-se de que é importante beber água suficiente ao longo do dia, mas também é importante não exceder as necessidades individuais.\n",
      "\n",
      "Todos os testes completados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from src.ollama_client import OllamaClient\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    client = OllamaClient()\n",
    "    \n",
    "    print(\"=== Teste de listagem de modelos ===\")\n",
    "    try:\n",
    "        models = client.list_models()\n",
    "        print(f\"Modelos disponíveis: {models}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao listar modelos: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if not models:\n",
    "        print(\"Nenhum modelo disponível. Servidor Ollama está rodando?\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(\"\\n=== Teste de chamada básica ===\")\n",
    "    try:\n",
    "        response = client.call(\n",
    "            model=models[0],\n",
    "            prompt=\"Explique o que é uma API REST em 1 frase\",\n",
    "            system_prompt=\"Seja conciso e técnico\"\n",
    "        )\n",
    "        print(f\"Resposta: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na chamada ao modelo: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(\"\\n=== Teste de streaming ===\")\n",
    "    try:\n",
    "        stream_response = client.call(\n",
    "            model=models[0],\n",
    "            prompt=\"Liste 3 benefícios de beber água\",\n",
    "            stream=True\n",
    "        )\n",
    "        print(f\"Resposta em streaming: {stream_response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no streaming: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(\"\\nTodos os testes completados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98f05ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mollama_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaClient\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatabaseClient\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_wait_suspend(thread, frame, event, arg)\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdo_wait_suspend(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.ollama_client import OllamaClient\n",
    "from src.database_client import DatabaseClient\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import requests\n",
    "import re\n",
    "import sqlglot\n",
    "from sqlglot.expressions import Column\n",
    "from sqlglot.errors import ParseError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.ollama_base_url = \"http://localhost:11434\"\n",
    "        self.database = DatabaseClient()\n",
    "        #tem que estar em inglês\n",
    "        self.table_schema = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS metric (\n",
    "            time TIMESTAMPTZ NOT NULL PRIMARY KEY, -- Metric timestamp\n",
    "            fivegs_amffunction_rm_registeredsubnbr INT, -- Number of registered subscribers\n",
    "            fivegs_amffunction_rm_regmobreq INT, -- Mobility registration update requests\n",
    "            fivegs_amffunction_rm_regmobsucc INT, -- Successful mobility registration updates\n",
    "            fivegs_amffunction_rm_regmobfail INT, -- Failed mobility registration updates\n",
    "            fivegs_smffunction_sm_sessionnbr INT, -- Number of active sessions\n",
    "            fivegs_smffunction_sm_pdusessioncreationreq INT, -- PDU session creation requests\n",
    "            fivegs_smffunction_sm_pdusessioncreationsucc INT, -- Successful PDU session creations\n",
    "            fivegs_ep_n3_gtp_indatapktn3upf INT, -- Uplink throughput on N3 interface\n",
    "            fivegs_ep_n3_gtp_outdatapktn3upf INT, -- Downlink throughput on N3 interface\n",
    "            fivegs_upffunction_upf_sessionnbr INT, -- Average number of PDU sessions\n",
    "            fivegs_smffunction_upf_qos_flow_nbr INT, -- Number of active QoS flows\n",
    "            fivegs_upffunction_sm_n4sessionreport INT, -- N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionreportsucc INT, -- Successful N4 session reports\n",
    "            fivegs_upffunction_sm_n4sessionestabreq INT, -- N4 session establishment requests\n",
    "            fivegs_upffunction_sm_n4sessionestabfail INT, -- Failed N4 session establishments\n",
    "            softmodern_bler_dl INT, -- Block error rate - downlink\n",
    "            softmodern_bler_ul INT, -- Block error rate - uplink\n",
    "            softmodern_rsrp INT, -- Received signal power\n",
    "            pfcp_sessions_active INT -- Used for testing value changes\n",
    "        );\n",
    "        Get the current 5G network performance metrics, including throughput, latency and packet loss rates.\n",
    "        \"\"\"\n",
    "        \n",
    "    def call_ollama(self, model : str, prompt : str, system_prompt: str = None) -> str:\n",
    "\n",
    "        try:\n",
    "            url = f\"{self.ollama_base_url}/api/generate\"\n",
    "            payload = {\n",
    "                \"model\": model,\n",
    "                \"prompt\":prompt,\n",
    "                \"stream\":False,\n",
    "                \"options\":{\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"num_predict\": 1000\n",
    "                }\n",
    "            }\n",
    "            if system_prompt:\n",
    "                payload[\"system\"] = system_prompt\n",
    "            response = requests.post(url, json=payload, timeout=120)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            return response.json()[\"response\"].strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def translate_and_process_question(self, question: str) -> str:\n",
    "        system_prompt = \"\"\"\n",
    "        Você é um assistente especializado em tradução e processamento de perguntas para consultas SQL.\n",
    "        Sua tarefa é:\n",
    "        1. Traduzir a pergunta do português para o inglês\n",
    "        2. Reformular a pergunta para ser mais específica e clara para geração de SQL\n",
    "        3. Incluir contexto técnico relevante sobre métricas de redes 5G quando apropriado\n",
    "        4. Manter o significado original mas torná-la mais precisa\n",
    "        \n",
    "        Responda apenas com a pergunta traduzida e processada, sem explicações adicionais.\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Pergunta original em português: \"{question}\"\n",
    "        \n",
    "        Traduza para inglês e processe para ser mais específica para geração de SQL sobre métricas de rede 5G.\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(\"Etapa 1: Traduzindo e processando pergunta...\")\n",
    "        processed_question = self.call_ollama(\"llama3.2:latest\", prompt, system_prompt)\n",
    "        logger.info(f\"Pergunta processada: {processed_question}\")\n",
    "        \n",
    "        return processed_question\n",
    "    \n",
    "    def execute_sql_query(self, sql_query: str) -> Tuple[list, str]:\n",
    "        try:\n",
    "            logger.info(\"Etapa 3: Executando query SQL...\")\n",
    "            return self.database.execute(sql_query)                    \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erro ao executar query SQL: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return [], error_msg\n",
    "\n",
    "    def generate_sql_query(self, processed_question: str, max_retries: int = 3) -> str:\n",
    "        system_prompt = \"\"\"\n",
    "        You are an expert SQL query generator for PostgreSQL. Generate precise SQL queries based on the user's question.\n",
    "        Always use proper SQL syntax and consider performance optimizations.\n",
    "        Focus on the specific metrics requested and use appropriate aggregations and filters.\n",
    "        Return only the SQL query without any explanations or markdown formatting.\n",
    "        \"\"\"\n",
    "\n",
    "        available_columns = self._extract_column_names()\n",
    "\n",
    "        base_prompt = f\"\"\"\n",
    "        Database schema:\n",
    "        {self.table_schema}\n",
    "\n",
    "        Available columns in 'metric' table:\n",
    "        {', '.join(available_columns)}\n",
    "\n",
    "        User question: {processed_question}\n",
    "\n",
    "        Generate a SQL query to answer this question. Consider:\n",
    "        - The table name is 'metric'\n",
    "        - Use appropriate time filtering when needed\n",
    "        - Apply proper aggregations (SUM, AVG, COUNT, etc.)\n",
    "        - Include relevant columns based on the question\n",
    "        - Use proper PostgreSQL syntax\n",
    "        - ONLY use column names that exist in the available columns list above\n",
    "\n",
    "        Important constraints:\n",
    "        - Table name: 'metric'\n",
    "        - Time column: 'time' (TIMESTAMPTZ)\n",
    "        - NEVER use nested aggregate functions like AVG(SUM(...))\n",
    "        - Use subqueries for complex aggregations\n",
    "        - Use proper time filtering with PostgreSQL date functions\n",
    "        - Include appropriate GROUP BY clauses\n",
    "        - Use LIMIT when showing recent data\n",
    "        - NEVER use aggregate functions in GROUP BY clause\n",
    "        - Only reference columns that exist in the available columns list\n",
    "\n",
    "        Examples of VALID patterns:\n",
    "        - SELECT AVG(column_name) FROM metric WHERE time >= NOW() - INTERVAL '1 hour'\n",
    "        - SELECT date_trunc('hour', time), SUM(column_name) FROM metric GROUP BY date_trunc('hour', time)\n",
    "        - SELECT AVG(daily_total) FROM (SELECT DATE(time), SUM(column_name) as daily_total FROM metric GROUP BY DATE(time)) subq\n",
    "        - SELECT time, column_name FROM metric ORDER BY time DESC LIMIT 10\n",
    "\n",
    "        Examples of INVALID patterns (DO NOT USE):\n",
    "        - SELECT AVG(SUM(column_name)) FROM metric -- INVALID: nested aggregates\n",
    "        - SELECT SUM(AVG(column_name)) FROM metric -- INVALID: nested aggregates\n",
    "        - SELECT time, SUM(column_name) FROM metric GROUP BY COUNT(other_column) -- INVALID: aggregate in GROUP BY\n",
    "        - SELECT nonexistent_column FROM metric -- INVALID: column doesn't exist\n",
    "\n",
    "        Generate only the SQL query:\n",
    "        \"\"\"\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < max_retries:\n",
    "            logger.info(f\"Etapa 2: Tentativa {attempt + 1} de {max_retries} para gerar query SQL...\")\n",
    "            sql_query = self.call_ollama(\"llama3.2:latest\", base_prompt, system_prompt)\n",
    "\n",
    "            sql_query = re.sub(r'```sql\\n?', '', sql_query)\n",
    "            sql_query = re.sub(r'```\\n?', '', sql_query)\n",
    "            sql_query = sql_query.strip()\n",
    "\n",
    "            validation_errors = self._validate_sql_query(sql_query, available_columns)\n",
    "            if not validation_errors:\n",
    "                logger.info(f\"Query SQL gerada com sucesso: {sql_query}\")\n",
    "                return sql_query\n",
    "            else:\n",
    "                logger.warning(f\"Tentativa {attempt + 1} falhou com erros: {validation_errors}\")\n",
    "                attempt += 1\n",
    "\n",
    "        logger.error(\"Falha ao gerar uma query SQL válida após várias tentativas.\")\n",
    "        raise ValueError(\"Não foi possível gerar uma query SQL válida.\")\n",
    "\n",
    "\n",
    "    def _extract_column_names(self) -> list:\n",
    "        \"\"\"Extract column names from the table schema\"\"\"\n",
    "        try:\n",
    "\n",
    "            columns = []\n",
    "            if hasattr(self, 'table_schema') and self.table_schema:\n",
    "                if isinstance(self.table_schema, str):\n",
    "                    import re\n",
    "                    column_matches = re.findall(r'(\\w+)\\s+(?:INTEGER|VARCHAR|TEXT|TIMESTAMPTZ|NUMERIC|FLOAT|DOUBLE)', \n",
    "                                            self.table_schema, re.IGNORECASE)\n",
    "                    columns = column_matches\n",
    "                \n",
    "            if not columns:\n",
    "                try:\n",
    "                    query = \"\"\"\n",
    "                    SELECT column_name \n",
    "                    FROM information_schema.columns \n",
    "                    WHERE table_name = 'metric' \n",
    "                    ORDER BY ordinal_position\n",
    "                    \"\"\"\n",
    "                    result = self.db_client.execute_query(query)\n",
    "                    columns = [row[0] for row in result]\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not fetch column names: {e}\")\n",
    "                    columns = ['time']\n",
    "            \n",
    "            return columns\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting column names: {e}\")\n",
    "            return ['time']\n",
    "\n",
    "    def _validate_sql_query(self, sql_query: str, available_columns: list) -> list:\n",
    "        \"\"\"Validate the SQL query for common issues\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if re.search(r'(AVG|SUM|COUNT|MIN|MAX)\\s*\\(\\s*(AVG|SUM|COUNT|MIN|MAX)', sql_query, re.IGNORECASE):\n",
    "            errors.append(\"Nested aggregate functions detected\")\n",
    "        \n",
    "        group_by_match = re.search(r'GROUP BY\\s+(.+?)(?:\\s+ORDER|\\s+HAVING|\\s+LIMIT|$)', sql_query, re.IGNORECASE | re.DOTALL)\n",
    "        if group_by_match:\n",
    "            group_by_clause = group_by_match.group(1)\n",
    "            if re.search(r'(AVG|SUM|COUNT|MIN|MAX)\\s*\\(', group_by_clause, re.IGNORECASE):\n",
    "                errors.append(\"Aggregate function in GROUP BY clause\")\n",
    "        \n",
    "\n",
    "        column_refs = re.findall(r'\\b(?!(?:SELECT|FROM|WHERE|GROUP|ORDER|BY|HAVING|LIMIT|AND|OR|NOT|IN|EXISTS|CASE|WHEN|THEN|ELSE|END|AS|DISTINCT|ALL|UNION|INTERSECT|EXCEPT|JOIN|LEFT|RIGHT|INNER|OUTER|ON|USING|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP|TRUNCATE|GRANT|REVOKE)\\b)\\w+\\b', sql_query, re.IGNORECASE)\n",
    "        \n",
    "        sql_keywords = {'metric', 'time', 'now', 'interval', 'date', 'extract', 'date_trunc', 'hour', 'day', 'month', 'year', 'desc', 'asc', 'null', 'true', 'false'}\n",
    "        potential_columns = [col for col in column_refs if col.lower() not in sql_keywords and not col.isdigit()]\n",
    "        \n",
    "        missing_columns = [col for col in potential_columns if col not in available_columns]\n",
    "        if missing_columns:\n",
    "            errors.append(f\"Potential missing columns: {missing_columns}\")\n",
    "        \n",
    "        return errors\n",
    "\n",
    "    def interpret_results(self, original_question: str, sql_query: str, \n",
    "                         results: list, execution_status: str) -> str:\n",
    "        system_prompt = \"\"\"\n",
    "        Você é um assistente especializado em análise de dados de redes 5G.\n",
    "        Sua tarefa é interpretar os resultados de consultas SQL e fornecer uma resposta clara em português.\n",
    "        \n",
    "        Diretrizes:\n",
    "        1. Responda em português brasileiro\n",
    "        2. Seja claro e objetivo\n",
    "        3. Forneça insights relevantes sobre os dados\n",
    "        4. Explique o que os números significam no contexto de redes 5G\n",
    "        5. Se houver problemas com a query, explique de forma compreensível\n",
    "        6. Use formatação clara para apresentar os dados\n",
    "        \"\"\"\n",
    "        \n",
    "        if results:\n",
    "            results_summary = f\"Resultados encontrados: {len(results)} registros\\n\"\n",
    "            results_summary += f\"Primeiros resultados:\\n{json.dumps(results[:5], indent=2, default=str)}\"\n",
    "        else:\n",
    "            results_summary = \"Nenhum resultado encontrado ou erro na execução.\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Pergunta original do usuário: \"{original_question}\"\n",
    "        \n",
    "        Query SQL executada: {sql_query}\n",
    "        \n",
    "        Status da execução: {execution_status}\n",
    "        \n",
    "        {results_summary}\n",
    "        \n",
    "        Forneça uma resposta completa em português interpretando estes resultados para o usuário.\n",
    "        Se houver dados, analise-os e forneça insights relevantes.\n",
    "        Se houver erros, explique o que aconteceu de forma compreensível.\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(\"Etapa 4: Interpretando resultados...\")\n",
    "        interpretation = self.call_ollama(\"llama3.2:latest\", prompt, system_prompt)\n",
    "        \n",
    "        return interpretation\n",
    "\n",
    "    def process_question(self, question: str):\n",
    "        start_time = datetime.now()\n",
    "        try:\n",
    "            processed_question = self.translate_and_process_question(question)\n",
    "\n",
    "            sql_query = self.generate_sql_query(processed_question)\n",
    "\n",
    "            results, execution_status = self.execute_sql_query(sql_query)\n",
    "\n",
    "            interpretation = self.interpret_results(\n",
    "                question, sql_query, results, execution_status\n",
    "            )\n",
    "\n",
    "            end_time = datetime.now()\n",
    "            processing_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"original_question\": question,\n",
    "                \"processed_question\": processed_question,\n",
    "                \"sql_query\": sql_query,\n",
    "                \"execution_status\": execution_status,\n",
    "                \"results_count\": len(results),\n",
    "                \"results\": results,\n",
    "                \"interpretation\": interpretation,\n",
    "                \"processing_time_seconds\": processing_time,\n",
    "                \"timestamp\": start_time.isoformat()\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_msg = f\"Erro no pipeline: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            \n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": error_msg,\n",
    "                \"original_question\": question,\n",
    "                \"timestamp\": start_time.isoformat()\n",
    "            }\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e777f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2025, 7, 10, 22, 47, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 44, 45, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 40, 16, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 42, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 46, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 43, 30, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 40, 30, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 48, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 42, 15, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "(datetime.datetime(2025, 7, 10, 22, 45, tzinfo=datetime.timezone.utc), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from metrics_dict import metrics_dict\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "        host=\"172.22.0.40\",\n",
    "        port=5432,\n",
    "        database=\"metrics\",\n",
    "        user=\"admin\",\n",
    "        password=\"admin123\"\n",
    "        )\n",
    "\n",
    "cur = connection.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_schema, table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_type = 'BASE TABLE'\n",
    "        AND table_schema NOT IN ('pg_catalog', 'information_schema')\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT * FROM metric LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "result = cur.fetchall()\n",
    "for index in result:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2d42f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(resultado: Dict[str, Any]) -> None:\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"RESULTADO DO PIPELINE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        if resultado[\"success\"]:\n",
    "            print(f\"Status: Processamento concluído com sucesso\")\n",
    "            print(f\"Tempo: {resultado['processing_time_seconds']:.2f} segundos\")\n",
    "            print(f\"Registros encontrados: {resultado['results_count']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"PERGUNTA ORIGINAL:\")\n",
    "            print(f\"{resultado['original_question']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"PERGUNTA PROCESSADA:\")\n",
    "            print(f\"{resultado['processed_question']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"QUERY SQL GERADA:\")\n",
    "            print(f\"{resultado['sql_query']}\")\n",
    "            print()\n",
    "            \n",
    "            print(\"INTERPRETAÇÃO DOS RESULTADOS:\")\n",
    "            print(\"-\" * 50)\n",
    "            interpretation_lines = resultado['interpretation'].split('\\n')\n",
    "            for line in interpretation_lines:\n",
    "                print(f\"   {line}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Status: Erro no processamento\")\n",
    "            print(f\" Erro: {resultado['error']}\")\n",
    "            print(f\"Pergunta: {resultado['original_question']}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc90aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Number of active subscribers in the 5G network.\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n",
      "ERROR:__main__:Erro no pipeline: expected string or bytes-like object, got 'NoneType'\n",
      "INFO:__main__:Etapa 1: Traduzindo e processando pergunta...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120)\n",
      "expected string or bytes-like object, got 'NoneType'\n",
      "Bola furada...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pergunta processada: \"Which is the session PDU success rate for the last week in 5G network?\"\n",
      "INFO:__main__:Etapa 2: Tentativa 1 de 3 para gerar query SQL...\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline()\n",
    "\n",
    "perguntas_exemplo = [\n",
    "        \"Quantos assinantes estão registrados atualmente?\",\n",
    "        \"Qual é a taxa de sucesso das sessões PDU na última semana?\",\n",
    "        \"Mostre o throughput médio de upload e download nas últimas 24 horas\",\n",
    "        \"Qual é a taxa de erro de bloco para uplink e downlink hoje?\",\n",
    "        \"Quantas sessões ativas existem no momento?\"\n",
    "    ]\n",
    "for pergunta in perguntas_exemplo:\n",
    "    resultado = pipe.process_question(pergunta)\n",
    "    if resultado[\"success\"]:\n",
    "        print(f\"Processamento concluído em {resultado['processing_time_seconds']:.2f}s\")\n",
    "        print(f\"Resultados encontrados: {resultado['results_count']}\")\n",
    "        print(f\"Query SQL: {resultado['sql_query']}\")\n",
    "        print(f\"Interpretação: {resultado['interpretation']}\")\n",
    "    else:\n",
    "        print(f\"Bola furada...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3d73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
